# HDFS 直接读取本地数据

官方文档：https://hadoop.apache.org/docs/r3.3.0/hadoop-project-dist/hadoop-hdfs/ShortCircuitLocalReads.html

在`HDFS中`，读取通常通过`DataNode进行`。因此，当客户端要求`DataNode`读取文件时，`DataNode将从`磁盘上读取该文件，然后通过TCP套接字将数据发送给客户端。所谓的“短路”读取绕过了`DataNode`，从而允许客户端直接读取文件。显然，这仅在客户端与数据位于同一位置的情况下才可能。短路读取为许多应用提供了显着的性能提升。

要配置短路本地读取，需要启用`libhadoop.so`，参考：[本地库](https://hadoop.apache.org/docs/r3.3.0/hadoop-project-dist/hadoop-common/NativeLibraries.html)

短路读取利用UNIX域套接字。这是文件系统中的一条特殊路径，它允许客户端和`DataNode`进行通信。您将需要为此套接字设置一个路径。该`数据节点`需要能够创建此路径。另一方面，除HDFS用户或root之外，任何其他用户都不可能创建该路径。因此，通常使用`/var/run`或`/var/lib`下的路径。

客户端和`DataNode`通过`/dev/shm`上的共享内存段交换信息。

短路本地读取需要同时在`DataNode`和客户端上配置。

新版本 HDFS 配置示例：

```xml
<configuration>
  <property>
    <name>dfs.client.read.shortcircuit</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.domain.socket.path</name>
    <value>/var/lib/hadoop-hdfs/dn_socket</value>
  </property>
</configuration>
```

