# 管理 Cursh Map

官方文档：https://ceph.readthedocs.io/en/latest/rados/operations/crush-map/

CRUSH 算法通过计算数据存储位置来确定如何存储和检索数据。CRUSH使Ceph客户端能够直接与OSD通信，而不是通过 Monitor 进行通信。

通过算法确定的存储和检索数据的方法，Ceph避免了单点故障，性能瓶颈以及对其可扩展性的物理限制。

CRUSH需要群集的映射，并使用CRUSH映射伪随机地存储和检索OSD中的数据，并使数据在整个群集中均匀分布。

CRUSH 论文：https://ceph.com/wp-content/uploads/2016/08/weil-crush-sc06.pdf



CRUSH Map 包含 OSD 列表、物理设备列表、及规则列表。通过对底层物理设备的组织，Crush 可以对潜在故障进行建模，典型的组织方式包括物理距离、共享的电源和共享的网络等。通过将此信息编码到群集映射中，CRUSH放置策略可以将对象副本复制到不同的故障域中。例如，为了解决并发故障的可能性，可能需要确保数据副本位于使用不同的机架，电源，控制器和/或物理位置的设备上。

部署OSD时，它们会自动放置在CRUSH映射中的主机节点下，该主机节点以其运行的主机的主机名命名。这与默认的CRUSH故障域结合在一起，可确保副本或纠删码在主机之间是分开的，并且单个主机故障不会影响可用性。但是，对于较大的群集，管理员应仔细考虑他们对故障域的选择。例如，在中大型集群中，跨机架分隔副本很常见。



## Crush 位置

OSD在CRUSH Map层次结构方面的位置称为“crush location”。该位置说明符采用描述位置的键和值对列表的形式。例如，如果一个OSD位于特定的行，机架，机箱和主机中，并且是“默认” CRUSH树的一部分（绝大多数集群就是这种情况），则其损坏位置可以描述为：

```
root=default row=a rack=a2 chassis=a2a host=a2a1
```









