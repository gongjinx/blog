# 纠删码

官方文档：https://ceph.readthedocs.io/en/latest/rados/operations/erasure-code/

Ceph池与一种类型相关联以承受OSD（即磁盘的丢失），因为大多数情况下每个磁盘上只有一个OSD。创建池时的默认选择是复制的，这意味着每个对象都复制到多个磁盘上。可以使用纠删码池类型来节省空间。



## 创建使用纠删码的 Pool

最简单的擦除编码池等效于RAID5，并且至少需要三个主机：

```bash
$ ceph osd pool create ecpool erasure
pool 'ecpool' created
$ echo ABCDEFGHI | rados --pool ecpool put NYAN -
$ rados --pool ecpool get NYAN -
ABCDEFGHI
```



## 纠删码配置

默认的纠删码配置文件会丢失两个OSD。它等效于大小为3的复制池，但需要2TB而不是3TB的数据来存储1TB的数据。默认配置文件可以显示为：

```bash
$ ceph osd erasure-code-profile get default
k=2
m=2
plugin=jerasure
crush-failure-domain=host
technique=reed_sol_van
```

选择正确的配置文件很重要，因为在创建池后无法对其进行修改：需要创建一个具有不同配置文件的新池，并且将先前池中的所有对象都移到新的池中。

配置文件的最重要参数是K，M和 crush-failure-domain ，因为它们定义了存储开销和数据持久性。例如，如果所需的体系结构必须承受两个机架的丢失，而存储开销为开销的67％，则可以定义以下配置文件：

```bash
$ ceph osd erasure-code-profile set myprofile \
   k=3 \
   m=2 \
   crush-failure-domain=rack
$ ceph osd pool create ecpool erasure myprofile
$ echo ABCDEFGHI | rados --pool ecpool put NYAN -
$ rados --pool ecpool get NYAN -
ABCDEFGHI
```

NYAN对象将分为三个（K = 3），并且将创建两个附加的块（M = 2）。 M的值定义了在不丢失任何数据的情况下可以同时丢失多少个OSD。crush-failure-domain=rack创建一个CRUSH规则，以确保没有两个块存储在同一机架中。



## 带 OVERWRITES 的纠删码

默认情况下，擦除编码池仅适用于执行完整对象写入和追加的RGW之类的用途。

从 Luminous 版本之后，可以通过每个池设置启用纠删码池的部分写入。这使RBD和CephFS将其数据存储在纠删码池中：

```bash
$ ceph osd pool set ec_pool allow_ec_overwrites true
```

只有在 bluestore OSD 上的池上才能启用此功能，因为 bluestore 的校验和用于检测深度擦除期间的位腐或其他损坏。除了不安全之外，将文件存储区与ec覆盖一起使用还比bluestore产生较低的性能。

纠删池不支持omap，因此要将它们与RBD和CephFS一起使用，必须指示它们将数据存储在纠删码池中，并将元数据存储在复制池中。

```bash
$ rbd create --size 1G --data-pool ec_pool replicated_pool/image_name
```

对于CephFS，可以在文件系统创建过程中或通过文件布局将擦除编码池设置为默认数据池。



## 纠删码和缓存分层

擦除编码池比复制池需要更多的资源，并且缺少某些功能，例如omap。为了克服这些限制，可以在擦除编码池之前设置一个缓存层。

例如，如果池热存储由快速存储组成：

```bash
$ ceph osd tier add ecpool hot-storage
$ ceph osd tier cache-mode hot-storage writeback
$ ceph osd tier set-overlay ecpool hot-storage
```

会将热存储池作为ecpool的层置于写回模式，以便对ecpool的每次写入和读取实际上都在使用该热存储，并从其灵活性和速度中受益。









